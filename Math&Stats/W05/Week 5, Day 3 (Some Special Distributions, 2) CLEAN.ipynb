{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ready-treasurer",
   "metadata": {
    "id": "ready-treasurer"
   },
   "source": [
    "# Week 5: Probability Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spare-ultimate",
   "metadata": {
    "id": "spare-ultimate"
   },
   "outputs": [],
   "source": [
    "# Loading the libraries\n",
    "import numpy as np\n",
    "import sympy as sy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-dylan",
   "metadata": {
    "id": "careful-dylan"
   },
   "source": [
    "## Days 2 and 3: Some Special Probability Distributions\n",
    "\n",
    "Today we continue with some continuous distributions which appear frequently in statistical analysis and in machine learning\n",
    "\n",
    "### Normal Distribution\n",
    "The **Normal Distribution** goes by many names, and most people have heard about it. It is also known as **Gaussian Distribution** or **Bell-Curve**. The normal distribution has two parameters: the *location* parameter which is defined by the **mean** $\\mu$ of the distribution (and is the most likely outcome), and the *scale* parameter which is defined by the **variance** $\\sigma^2$ or **standard deviation** $\\sigma$ of the distribution (which determines the horizontal stretch of the distribution). If a random variable $X$ follows a normal distribution with mean $\\mu$ and standard deviation $\\sigma$, we write:\n",
    "\\begin{equation} X \\sim \\mathcal{N}(\\mu, \\sigma) \\end{equation}\n",
    "For any such random variable, $X \\in (-\\infty, \\infty)$ and the pdf is given by:\n",
    "\\begin{equation} f(x \\mid \\mu, \\sigma) = \\displaystyle \\frac{1}{\\sqrt{2\\pi}\\cdot \\sigma}~\\exp\\left( {-\\frac{1}{2} ~ \\left( \\frac{x - \\mu}{\\sigma} \\right)^2} \\right) \\end{equation}\n",
    "\n",
    "Every Normal distribution has a unique definiing property known as **68-95-99.7 Rule** or **Empirical Rule** which relates the mean, the standard deviation, and the normal probabilities:\n",
    "\\begin{equation}\n",
    "\\begin{array}{rcl}\n",
    "P \\big(\\mu - \\sigma \\leqslant X \\leqslant \\mu + \\sigma \\big) &\\approx& 0.68\\\\\n",
    "P \\big(\\mu - 2\\sigma \\leqslant X \\leqslant \\mu + 2\\sigma \\big) &\\approx& 0.95\\\\\n",
    "P \\big(\\mu - 3\\sigma \\leqslant X \\leqslant \\mu + 3\\sigma \\big) &\\approx& 0.997\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "In other words: only the outcomes which are **within 3 standard deviations of the mean** are relevant, all other outcomes occur so rarely that they can, most frequently, be disregarded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-rachel",
   "metadata": {
    "id": "divided-rachel"
   },
   "source": [
    "### Example 1: Normal Distribution\n",
    "The weights of babies born at Prince Louis Maternity Hospital last year averaged $\\mu = 3.0$ kg with a standard deviation of $\\sigma = 200$ grams.\n",
    "* Visualize the distribution in the range $[\\mu - 4\\sigma, \\mu + 4\\sigma]$\n",
    "* What is the probability that a randomly selected baby born at the hospital weighs less than 3.2 kg?\n",
    "* If there were 545 babies born at this hospital last year, estimate the number of babies that weighed between 2.8 kg and 3.4 kg\n",
    "* Find the weight $w$ such that 40% of babies weigh less than $w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signal-manchester",
   "metadata": {
    "id": "signal-manchester"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-141a3b1c3ad1>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-141a3b1c3ad1>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    mu =\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# use scipy.stats.norm()\n",
    "# Define mu and sigma\n",
    "mu = \n",
    "sigma =  #in kilograms!\n",
    "weights_rv = \n",
    "\n",
    "# Visualize the distribution\n",
    "xs = np.linspace(mu-4*sigma, mu+4*sigma, 1000)\n",
    "plt.figure()\n",
    "plt.plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-jefferson",
   "metadata": {
    "id": "imported-jefferson"
   },
   "source": [
    "### Example 2: Normal Distribution\n",
    "The heights of a group of students are normally distributed with a mean of 160 cm and a standard deviation of 20 cm.\n",
    "* A student is chosen at random. Find the probability that the studentâ€™s height is greater than 180 cm.\n",
    "* In this group of students, 11.9% have heights less than $d$ cm. Find the value of $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-explorer",
   "metadata": {
    "id": "federal-explorer"
   },
   "outputs": [],
   "source": [
    "# Define the parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-ethics",
   "metadata": {
    "id": "short-ethics"
   },
   "source": [
    "### The Standard Normal Distribution\n",
    "The **Standard Normal Distribution** $Z$ is the the normal distribution with $\\mu =0 $ and $\\sigma = 1$:\n",
    "\\begin{equation} Z \\sim \\mathcal{N}(0, 1) \\end{equation}\n",
    "It can be used as a \"unversal comparison tool\" between all possible normal distributions via the process called **standardization** (recall $z$-scores from descriptive statistics)\n",
    "\n",
    "The relationship that scales a random variable $X \\sim \\mathcal{N}(\\mu, \\sigma)$ to $Z \\sim \\mathcal{N}(0, 1)$ is given by\n",
    "\\begin{equation} Z = \\frac{X - \\mu}{\\sigma} \\end{equation}\n",
    "This means that all questions about any normally distributed random variable $X$ can be answered using calculations for the standard normal distribution $Z$. Historically, the statistical tables for normal distribution contained only values about $Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-diana",
   "metadata": {
    "id": "noticed-diana"
   },
   "source": [
    "### Example 3\n",
    "A certain college requires a score of 900 on the GBT test for admission, but it will also accept an equivalent grade on the MRST test. The mean score on the GBT is 1020 and the standard deviation is 140; the mean score on the MRST is 21 and the standard deviation is 4.7. What is the minimum score on the MRST that the college will accept?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metric-fisher",
   "metadata": {
    "id": "metric-fisher"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19568296915377598\n",
      "16.97142857142857\n"
     ]
    }
   ],
   "source": [
    "## Define the normal variables\n",
    "# G ~ N(1020, 140)\n",
    "G = stats.norm(1020, 140)\n",
    "\n",
    "# M ~ N(21, 4.7)\n",
    "M = stats.norm(21, 4.7)\n",
    "\n",
    "# Get the cutoff percentile for GBT\n",
    "cutoff_perc = G.cdf(900)\n",
    "print(cutoff_perc)\n",
    "# Get the cutoff points for MRST\n",
    "cutoff_pts = M.ppf(cutoff_perc)\n",
    "print(cutoff_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-manhattan",
   "metadata": {
    "id": "personal-manhattan"
   },
   "source": [
    "### Example 4\n",
    "The weight loss, in kilograms, of people using the slimming regime SLIM3M for a period of three months is modelled by a random variable $X$. Experimental data showed that\n",
    "* 67% of the individuals using SLIM3M lost up to 5 kilograms, and\n",
    "* 12.4 % lost at least 7 kilograms\n",
    "\n",
    "Assuming that $X$ follows a Normal distribution, find the mean weight loss of a person who follows the SLIM3M regime for three months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excellent-smoke",
   "metadata": {
    "id": "excellent-smoke"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-22bc76e3e72d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0meq2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0msol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meq2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0msol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "# Define Z\n",
    "Z = stats.norm(0,1)\n",
    "z1 = Z.ppf(67)\n",
    "z2 = Z.ppf(1 - 0.124)\n",
    "\n",
    "#graph\n",
    "\n",
    "\n",
    "mu, sigma = sy.symbols('mu sigma', real = True)\n",
    "z1 = sy.sympify(z1)\n",
    "z2 = sy.sympify(z2)\n",
    "\n",
    "eq1 = sy.Eq((5-mu)/sigma, z1)\n",
    "eq2 = sy.Eq((7-mu)/sigma, z2)\n",
    "\n",
    "sol = mu, sigma = sy.solve((eq1, eq2), (mu, sigma))\n",
    "\n",
    "sol[mu], sol[sigma]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-aaron",
   "metadata": {
    "id": "adequate-aaron"
   },
   "source": [
    "### $\\chi^2$ Distirbution (chi-square)\n",
    "The chi-square distribution appears in the comparison of distributions, in the independence test, and homogeneity test (among others). If $Z_1, Z_2, \\ldots, Z_k$ are all standard normal variables independent of one another, then the variable\n",
    "\\begin{equation} \\chi_k^2 = Z_1^2 + Z_2^2 + \\ldots + Z_k^2 \\end{equation}\n",
    "follows $\\chi^2$-distribution with $k$ degrees of freedom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-dispatch",
   "metadata": {
    "id": "integral-dispatch"
   },
   "source": [
    "### Example 5\n",
    "Construct and visualize the $\\chi^2$-distributions for $k=1, 2, 3, 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-january",
   "metadata": {
    "id": "hearing-january"
   },
   "outputs": [],
   "source": [
    "# Defining chi_1^2, chi_2^2, chi_3^2 and chi_4^2\n",
    "\n",
    "# Visualize the distributions\n",
    "xs = np.linspace(0, 9, 1000)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-patent",
   "metadata": {
    "id": "ecological-patent"
   },
   "source": [
    "### Student's $t$ distribution\n",
    "Student's $t$ distribution appears in the statistical tests related to comparison of means and the ANOVA (ANalysis Of VAriance) framerork. It is key to analyzing symmetic data for fairly small samples.\n",
    "\n",
    "Let the random variables $Z$ and $\\chi_k^2$ be independent, with $Z$ being standard normal and $\\chi_k^2$ being a chi-square distribution with $k$ degrees of freedom. Then $t_k$, the $t$ distribution with $k$ degrees of freedom is defined as\n",
    "\\begin{equation}\n",
    "t_k = \\frac{Z}{\\sqrt{\\left.\\chi_k^2 \\middle/ k\\right.}}\n",
    "\\end{equation}\n",
    "The $t_k$ distribution is centeded at the zero and has a similar shape to the $Z$ distribution. $t_1$ is farthest from $Z$ and as $k$ increases, $t_k$ grows closer to $Z$. In the limit case: $t_k \\to Z$ as $k \\to \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-seafood",
   "metadata": {
    "id": "induced-seafood"
   },
   "source": [
    "### Example 6\n",
    "Construct and visualize $t_k$ for $k = 1, 5, 10, 40$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-afghanistan",
   "metadata": {
    "id": "composite-afghanistan"
   },
   "outputs": [],
   "source": [
    "# Defining t_k\n",
    "\n",
    "# Visualize the distributions\n",
    "xs = np.linspace(-4, 4, 1000)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Week 5, Day 3 (Some Special Distributions, 2) CLEAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
