{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "associate-seeker",
   "metadata": {},
   "source": [
    "# Week 1: Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "critical-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy\n",
    "import numpy as np\n",
    "import numpy.linalg as nla\n",
    "import scipy.linalg as sla\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-country",
   "metadata": {},
   "source": [
    "## Day 1: Vectors\n",
    "* Linear Algebra is part of mathematics that deals with the study of vectors and matrices.\n",
    "* Vectors can be thought of as lists/arrays of numbers\n",
    "* From a more abstract perspective, many objects in mathematics can be seen as \"vectors\".\n",
    "* We will only deal with vectors which are \"lists/arrays of (real) numbers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-liability",
   "metadata": {},
   "source": [
    "### Creating vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proper-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41421356, 3.16227766, 2.82842712])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating vectors with numpy.array\n",
    "\n",
    "a = np.array([1,0,2])\n",
    "\n",
    "b = np.array([0.5, 1.2, -3.0])\n",
    "\n",
    "c = np.array([np.sqrt(2),np.sqrt(10),2**1.5])\n",
    "\n",
    "O = np.zeros(3)\n",
    "\n",
    "e = np.ones(3)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "human-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# Vector dimensionality with .size and .shape\n",
    "\n",
    "print(c.size)\n",
    "\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-hormone",
   "metadata": {},
   "source": [
    "### Operations with vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fitting-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [1 0 2]\n",
      "b: [ 0.5  1.2 -3. ]\n",
      "[ 1.5  1.2 -1. ]\n",
      "[ 0.5 -1.2  5. ]\n",
      "[ 2.          0.         -0.66666667]\n",
      "[ 0.5  0.  -6. ]\n"
     ]
    }
   ],
   "source": [
    "# Component-wise operations (addition, subtraction, division)\n",
    "\n",
    "print (\"a:\", a)\n",
    "print (\"b:\", b)\n",
    "\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a/b)\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "explicit-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k*a [-2  0 -4]\n",
      "a/k [-0.5 -0.  -1. ]\n"
     ]
    }
   ],
   "source": [
    "# Scalar multiplication, i.e. scaling\n",
    "k = -2\n",
    "\n",
    "print(\"k*a\", k*a)\n",
    "print(\"a/k\", a/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mineral-reward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.62132034,  -4.74341649, -10.24264069])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining multiple operations\n",
    "\n",
    "a*b - 1.5*c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-vegetation",
   "metadata": {},
   "source": [
    "### Norms: Vectors Lengths\n",
    "* **Euclidean**, or **2-norm**: the usual distance in space. Given a vector  $v = (v_1, v_2, \\ldots, v_n)$,  its Euclidean norm $\\|v\\|_2$ is given by: \\begin{equation} \\|v\\|_2 = \\sqrt{v_1^2 + v_2^2 + \\ldots + v_n^2} = \\left( \\sum_{i=1}^{n} v_i^2 \\right) ^ {1/2}\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "driven-expression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.47213595499958"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating norms from scratch\n",
    "# Euclidean norm (usual length)\n",
    "# Pitagora on steroids\n",
    "def norm_of_vector(vector):\n",
    "    sum = 0\n",
    "    for i in range(len(vector)):\n",
    "        #print(i, vector[i])\n",
    "        sum += vector[i]**2\n",
    "        \n",
    "    return np.sqrt(sum)\n",
    "\n",
    "def norm_of_vector_Bojan(vector):\n",
    "    return np.sqrt((vector**2).sum())\n",
    "    \n",
    "# Test:\n",
    "v = np.array([3,4])\n",
    "norm_of_vector(c)\n",
    "norm_of_vector_Bojan(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-diabetes",
   "metadata": {},
   "source": [
    "* **Minkowski *p*-norm** is a generalization of the Euclidean norm. In short, substitute the 2's with *p*'s and you get a norm of order *p*. Note that $p \\geqslant 1$. Thus: \\begin{equation} \\|v\\|_p = \\left( \\sum_{i=1}^{n} \\left|v_i\\right|^p \\right) ^ {1/p}\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "driven-quarterly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4339305723653193"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minkowski's p-norm\n",
    "def pnorm_of_vector(vector, p):\n",
    "    sum = 0\n",
    "    for i in range(len(vector)):\n",
    "        #print(i, vector[i])\n",
    "        sum += abs(vector[i])**p\n",
    "        \n",
    "    return sum**(1/p)\n",
    "\n",
    "def pnorm_of_vector_Bojan(vector, p):\n",
    "    return np.power((np.power(np.absolute(vector), p)).sum(), 1/p)\n",
    "\n",
    "# Test\n",
    "v = np.array([-3,4,-5])\n",
    "pnorm_of_vector(b, 1.7)\n",
    "pnorm_of_vector_Bojan(b, 1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-pound",
   "metadata": {},
   "source": [
    "Special cases of the *p*-norms:\n",
    "\n",
    "* If $p=1$, then $\\|v\\|_1 = \\sum_{i=1}^{n} |v_i|$. This norm is called **taxicab** or **Manhattan norm**\n",
    "\n",
    "* If $p \\to \\infty$, then $\\|v\\|_\\infty = \\max\\big\\{ |v_1|, |v_2|, \\ldots, |v_n| \\big\\}$. This norm is called **max** or **Chebyshev norm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize our function to handle max- and Manhattan norms\n",
    "def pnorm(vector, p):\n",
    "    \n",
    "\n",
    "#Test\n",
    "pnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ignored-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4339305723653193"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using NumPy's numpy.linalg.norm(x, p)\n",
    "\n",
    "np.linalg.norm(b,1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a 'unit circle' under different norms\n",
    "# (unit circle = circle centered at the origin (0,0) with radius = 1)\n",
    "# we will use https://www.desmos.com/calculator to speed up things\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-philosophy",
   "metadata": {},
   "source": [
    "* Unit vectors: vectors whose norm is unit, i.e. equal to 1\n",
    "* This is a norm-dependent concept (depends on what norm we use to measure distances)\n",
    "* The process of \"converting\" a vector to a unit vector is called **normalization**. To normalize a vector $v$ we scalar multiply it by the reciprocal of its norm $\\|v\\|$. In short:\n",
    "\\begin{equation} v_{\\text{unit}} = \\frac{1}{\\|v\\|} \\cdot v \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-supplement",
   "metadata": {},
   "source": [
    "### Multiplying Vectors. Angle between two vectors\n",
    "* Multiplying vectors can be defined in multiple ways. Here we discuss only the **dot-product** of two vectors. If $a = (a_1, a_2, \\ldots, a_n)$ and $b = (b_1, b_2, \\ldots, b_n)$, then their dot-product is given by:\n",
    "\\begin{equation} a\\cdot b = a_1 b_1 + a_2 b_2 + \\ldots + a_n b_n \\end{equation}\n",
    "* The result of dot-multiplication of two vectors is a scalarm i.e. a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot-Product of two vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-accent",
   "metadata": {},
   "source": [
    "* If we \"normalize\" the dot-product of two vectors by dividing it by the product of the Euclidean norms of the vectors, then the resultin number is the **cosine of the angle** between the vectors. In other words, if $\\langle a, b \\rangle$ is the angle between the vectors $a$ and $b$, then:\n",
    "\\begin{equation} \\cos{\\langle a, b \\rangle} = \\frac{a \\cdot b}{\\|a\\|_2 \\cdot \\|b\\|_2} \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle between two vectors\n",
    "u = np.array([1, 0])\n",
    "v = np.array([2, 1])\n",
    "w = np.array([1, -1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-assurance",
   "metadata": {},
   "source": [
    "### Similarity between two vectors\n",
    "The cosine of the angle between two vectors can be used as a measure of **similarity** or **concordance**.\n",
    "* $\\cos{\\langle u, v \\rangle} \\approx 1 \\, \\Rightarrow \\,  \\langle u, v \\rangle \\approx 0$  (vectors in same general direction)\n",
    "* $\\cos{\\langle u, v \\rangle} \\approx 0 \\, \\Rightarrow \\,  \\langle u, v \\rangle \\approx 90^\\circ = \\frac{\\pi}{2}\\text{ rad}$ (vectors are close to perpendicular)\n",
    "* $\\cos{\\langle u, v \\rangle} \\approx -1 \\, \\Rightarrow \\,  \\langle u, v \\rangle \\approx 180^\\circ = \\pi \\text{ rad}$ (vectors are in almost opposite direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity between two vectors\n",
    "\n",
    "def cos_sim(v, w):\n",
    "    \n",
    "\n",
    "# Test\n",
    "x = np.array([1, 1, 1, 1])\n",
    "y = np.array([1.0, 0.5, 0.1, 2.4])\n",
    "cos_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity using scikit-learn (generates similarity matrix)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "z = np.array([0.5, 0.5, 0.5, 0.4])\n",
    "\n",
    "# Create a dataframe of vectors x, y and z\n",
    "data = {'x' : x, 'y' : y, 'z' : z}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "cosine_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of cosine simiparity application: text analysis\n",
    "# see: https://www.machinelearningplus.com/nlp/cosine-similarity/ for complete details\n",
    "\n",
    "# Step 1: Generate the documents\n",
    "doc_trump = 'Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin'\n",
    "doc_election = 'President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election'\n",
    "doc_putin = 'Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career'\n",
    "documents = [doc_trump, doc_election, doc_putin]\n",
    "\n",
    "\n",
    "# Step 2: Create the document matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['doc_trump', 'doc_election', 'doc_putin'])\n",
    "\n",
    "\n",
    "# Step 3: Calculate the cosine similarity for the dataframe df\n",
    "c_sim = cosine_similarity(df)\n",
    "print(c_sim)\n",
    "\n",
    "df_sim = pd.DataFrame(c_sim,\n",
    "                      columns = ['doc_trump', 'doc_election', 'doc_putin'])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(df_sim,\n",
    "            annot=True,\n",
    "            fmt='0.3f',\n",
    "            cmap='RdYlGn',\n",
    "            yticklabels=df_sim.columns\n",
    "           )\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-girlfriend",
   "metadata": {},
   "source": [
    "## Practice Assignment: the *iris* dataset\n",
    "The iris dataset contains data about the length and width of sepals and petals of three varieties of iris flowers (*setosa*, *versicolor* and *virginica*). This is a frequently used dataset in statistics and machine learning. Your task:\n",
    "* Load the dataset as a Pandas DataFrame\n",
    "* For every variety of iris flowers, construct the similarity matrix (e.g. a similarity matrix for the *setosa* variety, for the four vectors: sepal_length, sepal_width, petal_length, petal_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the iris dataset\n",
    "df_iris = pd.read_csv('iris.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
