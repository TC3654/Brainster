{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aca9f1f-ee8d-4ba0-832a-641d3bd25b88",
   "metadata": {},
   "source": [
    "# Week 8: Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053e9094-6029-4d5e-a5bd-f7edbce0896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the libraries\n",
    "import numpy as np\n",
    "#import sympy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as opt\n",
    "#from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa1168-28b0-47bc-8d40-75dcfe436f22",
   "metadata": {},
   "source": [
    "## Day 2: Maximum Likelihood Estimation\n",
    "\n",
    "So far we have been using probability distributions to calculate probabilities.\n",
    "\n",
    "For example, let's say that we toss a fair coin five times. if $H$ is the random variable that counts how many heads we got in the five tosses, then we can calculate the probability of getting four heads. In other words, since $H$ follows a binomial distribution with $n=5$ and $p=0.5$, i.e. $H \\sim \\mathcal{B}(5, 0.5)$, we can calculate that $P(H=4) = 0.15625$. This calculation means: *if you know the distribution and its parameters, then you can easily calculate the probabilities/likelihods for the outcomes*\n",
    "\n",
    "Now, let's turn the tables.\n",
    "\n",
    "Say we know that someone has been doing series of coin tosses, and has been counting the number of heads obtained in each of the series. The number of heads obtained are as such:\n",
    "$$1, 2, 2, 3, 4, 7$$\n",
    "We can immediately conclude, if $X$ is the number of heads in one series of tosses, that:\n",
    "* $X$ follows a binomial distribution (fixed number of independent success/failure trials with equal probability for success in each trial)\n",
    "* $X \\sim \\mathcal{B}(n, p)$, but we do not know $n$ and $p$\n",
    "* We could assume that $n=7$, the maximum number of heads observed in a single series. In other words, we assume this is a series in which all tosses turned up heads\n",
    "* The question next is: how do we figure out the value for $p$? This corresponds to the following quest: *if you know the distribution, and the outcomes, how can you estimate the parameters of the distribution?*\n",
    "\n",
    "The goal is, given some known distribution and some \"experimental\" data, to find the parameters of the distribution that is most likely to have produced the data. For our data this means that the outcomes above could have been produced by *any* binomial distribution $\\mathcal{B}(7, p)$, but we are interested in finding the value of $p$ such that the distribution with that value is most likely to have produced those outcomes.\n",
    "\n",
    "Given the quest, the method we use (today) to find the distribution is called **Maximum Likelihood** method, and the estimate of the parameters it produces are called **Maximum Likelihood Estmates (MLEs)**.\n",
    "\n",
    "\n",
    "### How does it work?\n",
    "Let $X$ be a random variable with some parameter $\\theta$ which we want to estimate, and let $p(X=x \\mid \\theta)$ be the probability density function of $X$. Let's assume that the data/outcomes we obtained are given in the set $D = \\{ x_1, x_2, \\ldots, x_n \\}$. Then the likelihood $\\text{lik}(D \\mid \\theta)$ of us observing that sequence of outcomes, assuming independence, is given as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{lik}(D \\mid \\theta) &= p(X=x_1 \\mid \\theta) \\cdot p(X=x_2 \\mid \\theta) \\cdot\\ldots\\cdot p(X=x_n \\mid \\theta) =\\\\\n",
    "&= \\prod_{i=1}^n p(X=x_i \\mid \\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "The maximum likelihood estimate of the parameter $\\theta$, denoted as $\\hat{\\theta}$, is given by:\n",
    "$$\n",
    "\\hat{\\theta} = \\max_{\\text{for all } \\theta} \\big\\{ \\text{lik}(D \\mid \\theta) \\big \\}\n",
    "$$\n",
    "From a practical standpoint, it is always better to to maximize the logarithm of the likelihoods via the so called **log-likelihood** function $L(D\\mid\\theta)$ which is given by:\n",
    "$$\n",
    "L(D\\mid\\theta) = \\ln \\big[ \\text{lik}(D \\mid \\theta) \\big]  = \\sum_{i=1}^n \\ln \\big[ p(X=x_i \\mid \\theta) \\big]\n",
    "$$\n",
    "so in that sense:\n",
    "$$\n",
    "\\hat{\\theta} = \\max_{\\text{for all } \\theta} \\big\\{ L(D \\mid \\theta) \\big\\}\n",
    "$$\n",
    "This means that to find the $\\hat\\theta$ we just have to define the likelihood or log-likehoood function and find its maximum using some optimization algorithm.\n",
    "\n",
    "## Example 1\n",
    "Six series of seven tosses of a coin are made. Let $X$ be the random variable that counts how many heads we get in each of the series. Then $X \\sim \\mathcal{B}(7, p)$. The results of the six series of tosses are:\n",
    "$$1, 2, 2, 3, 4, 7$$\n",
    "Estimate the most likely value for the parameter $p$ (in other words: find the maximum likelihood estimator of $p$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e352db4-ba68-451e-8f1d-9ed2d0faf019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[0.45234375],\n",
       "       [0.45244141]]), array([-1.0405456e-06, -1.0405454e-06]))\n",
       "           fun: -1.0405455997695717e-06\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 22\n",
       "           nit: 11\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([0.45234375])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the initial things\n",
    "heads = np.array([1, 2, 2, 3, 4, 7])\n",
    "n = 7\n",
    "p_0 = 0.5\n",
    "\n",
    "# Using lik\n",
    "def lik_bin(theta, data):\n",
    "    return -np.product(stats.binom(n, p=theta).pmf(data)) #minus in the begining is for the minimization to work\n",
    "\n",
    "lik_opt = opt.minimize(lik_bin,\n",
    "                       p_0,\n",
    "                       args=(heads),\n",
    "                       method='Nelder-Mead')\n",
    "\n",
    "lik_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940a799-001f-4206-af18-33b3bcc8d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using L\n",
    "def L(x, data):\n",
    "    return \n",
    "\n",
    "L_opt = opt.minimize(...)\n",
    "L_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c30d23-1226-42cc-9be4-a864a16c93f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the likelihood functions\n",
    "\n",
    "xs = np.linspace(0.01, 0.99, 1000)\n",
    "ys = ...\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a14451-767c-4e46-9370-eabad5ee2e10",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "Tim counts the number of cars running the red light at a traffic light. In seven consecutive observations he counts:\n",
    "$$\n",
    "0, 0, 0, 1, 1, 2, 3\n",
    "$$\n",
    "cars running on a red light. He finds it reasonable to assume that a Poisson distribution $Po(\\lambda)$ is appropriate to model the number of cars running the red light. If $X \\sim Po(\\lambda)$, then the densityfunction of $X$ is given by:\n",
    "$$\n",
    "p(X = k \\mid \\lambda) = \\frac{\\lambda^k}{k!} \\cdot e^{-\\lambda}\n",
    "$$\n",
    "for integer $k=0, 1, \\ldots$ and $\\lambda >0$.\n",
    "\n",
    "Help Tim calculate the maximum likelihood estimate $\\hat\\lambda$ of the mean number of cars running the red light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d113593c-1920-4009-badf-7bd54a17bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[0.99997559],\n",
       "       [1.00004883]]), array([9.48490665, 9.48490666]))\n",
       "           fun: 9.484906651874198\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 36\n",
       "           nit: 18\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([0.99997559])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the basic info\n",
    "cars = np.array([0, 0, 0, 1, 1, 2, 3])\n",
    "lambda_0 = 3.0\n",
    "\n",
    "def L(lmbd, data):\n",
    "    return -np.sum( np.log( stats.poisson(lmbd).pmf(data) ) )\n",
    "\n",
    "L_opt = opt.minimize(L, lambda_0, args=(cars), method='Nelder-Mead')\n",
    "\n",
    "L_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30931897-0056-441d-a65d-038019330adc",
   "metadata": {},
   "source": [
    "## Example 3\n",
    "This example is about modeling the accuracy of a certain rifle. Let's assume that the rifle is aimed at the center of a target which coincides with the origin $O$ of a coordinate system. 100 shots are made from a predetermined distance and the coordinates of the hits relative to $O$ are observed. These are given in the file `shooting_accuracy.csv`. All measurements are in decimeters (tens of centimeters).\n",
    "\n",
    "The *distances* between the center of the target and the hits follow a certain pattern. It can be shown that the distribution which describes this pattern is a **Rayleigh distribution**. This distribution has only one parameter, $\\sigma$, and a density function given by:\n",
    "$$\n",
    "p(x \\mid \\sigma) = \\frac{x}{\\sigma^2} \\cdot e^{-x^2 /(2\\sigma^2)}\n",
    "$$\n",
    "Based on the given data, find the maximum likelihood estimate of the parameter $\\sigma$ of the distribution that describes the distances between the center of the target and the hits for the rifle which is being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed541387-dde9-43f1-b7a1-cacb68f63a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df = pd.read_csv('shooting_accuracy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311ff1b-bfee-4cd1-8f6d-d5af1c32df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coordinates arrays\n",
    "\n",
    "\n",
    "# Calculate the distances\n",
    "\n",
    "\n",
    "# Plot the distances on a density histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d4666-68eb-45f7-8303-6085bc46bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the density function\n",
    "def rayleigh_pdf(x, sigma):\n",
    "    \n",
    "\n",
    "# Define the log-likehood function\n",
    "def L(x, data):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db076870-bd59-44ac-99de-67202b362401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the max of the log-likelihood\n",
    "sigma_0 = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d4690-7d72-4809-bcb3-f61035aed318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "# (the likelihood and the densitu fit over the data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955ec1f-33ac-49bd-93f5-d3cefead546c",
   "metadata": {},
   "source": [
    "## Example 4 (practice)\n",
    "The data in the data given below contains the time intervals (in minutes) between successive arrivals of customers at a checkout counter in a supermarket. In such cases experience has shown that an appropriate distribution to use for modeling is the **exponential distribution**. It has one parameter $\\theta >0$ and a density function:\n",
    "$$\n",
    "p(t \\mid \\theta) = \\tfrac{1}{\\theta} \\cdot e^{-t/\\theta}\n",
    "$$\n",
    "for $t \\geqslant 0$. Find the maximum likelihood estimate $\\hat\\theta$ of the parameter $\\theta$ for the exponential distribution that models the time intervals between arrivals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e6473-4eba-4855-9ccf-715f30fe2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times between arrivals\n",
    "times = np.array([1, 2, 3, 7, 11, 4, 13,\n",
    "                  12, 7, 3, 2, 11, 7, 2])\n",
    "\n",
    "# Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f4230-a4a4-4a70-9e34-8eeb2ff16f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1925cc70-3770-41df-b36e-eee480fa0f89",
   "metadata": {},
   "source": [
    "## Example 5\n",
    "Men in the Dinaric Alps region of the Balkan Peninsula are, on average, among the tallest men on the Earth. The file `dinaric_alps.csv` conains data about the heights of some men who were born and live in the region.\n",
    "\n",
    "Given the data, and assuming that heights follow a normal distribution in the population of men, use maximum likelihood estimation to estimate the mean $\\mu$ and the standard deviation $\\sigma$ of the heights in the population of men in the Dinaric Alps region.\n",
    "\n",
    "**Note:** the actual values are: `mu = 185.6` and `sigma = 7.42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07979a96-2a46-476c-b94a-a15c82136af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dinaric_alps.csv')\n",
    "display(df.head())\n",
    "\n",
    "#sns.histplot(data=df)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df['heights'], edgecolor='k', bins=6)\n",
    "plt.xlabel('heights')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b42fe1-25b5-4495-aef7-e137b493efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and find the MLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf1bb6-7eb4-4818-bb99-8a79798162cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
